{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD99 Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intrinsic attributes**\n",
    "\n",
    "These attributes are extracted from the headers' area of the network packets.\n",
    "\n",
    "Col|Feature name  | description |\ttype\n",
    "---|--------------|-------------|------------\n",
    "1  |duration \t  |length (number of seconds) of the connection |continuous\n",
    "2  |protocol_type |type of the protocol, e.g. tcp, udp, etc. |discrete\n",
    "3  |service \t  |network service on the destination, e.g., http, telnet, etc. |discrete\n",
    "4  |flag \t      |normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR \t|discrete \n",
    "5  |src_bytes \t  |number of data bytes from source to destination \t|continuous\n",
    "6  |dst_bytes \t  |number of data bytes from destination to source \t|continuous\n",
    "7  |land \t      |1 if connection is from/to the same host/port; 0 otherwise \t|discrete\n",
    "8  |wrong_fragment|sum of bad checksum packets in a connection \t|continuous\n",
    "9  |urgent \t      |number of urgent packets. Urgent packets are packets with the urgent bit activated \t|continuous\n",
    "\n",
    "\n",
    "**Class attribute**\n",
    "\n",
    "The 42nd attribute is the ***class_attack*** attribute, it indicates which type of connections is each instance: normal or which attack. The values it can take are the following: *anomaly, dict, dict_simple, eject, eject-fail, ffb, ffb_clear, format, format_clear, format-fail, ftp-write, guest, imap, land, load_clear, loadmodule, multihop, perl_clear, perlmagic, phf, rootkit, spy, syslog, teardrop, warez, warezclient, warezmaster, pod, back, ip- sweep, neptune, nmap, portsweep, satan, smurf and normal*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Categories of class attribute **\n",
    "\n",
    "\n",
    "class_attack |Category\n",
    "-------|--------------\n",
    "smurf| dos\n",
    "neptune| dos\n",
    "back| dos\n",
    "teardrop| dos\n",
    "pod| dos\n",
    "land| dos\n",
    "normal|normal\n",
    "satan|probe\n",
    "ipsweep|probe\n",
    "portsweep|probe\n",
    "nmap|probe\n",
    "warezclient|r2l\n",
    "guess_passwd|r2l\n",
    "warezmaster|r2l\n",
    "imap|r2l\n",
    "ftp_write|r2l\n",
    "multihop|r2l\n",
    "phf|r2l\n",
    "spy|r2l\n",
    "buffer_overflow|u2r\n",
    "rootkit|u2r\n",
    "loadmodule|u2r\n",
    "perl|u2r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/KDD/KDDTrain+.txt', header=None, usecols=[0,1,2,3,4,5,6,7,8,41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "                 \"wrong_fragment\",\"urgent\", \"class_attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS = data[['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', \n",
    "         'wrong_fragment', 'urgent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataLabels = pd.DataFrame(data['class_attack'], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataLabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding protocol_type **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS.protocol_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protocol_type_bin = pp.label_binarize(trainDS.protocol_type, \n",
    "                                      classes = trainDS.protocol_type.unique())\n",
    "protocol_type_DataFrame = pd.DataFrame(protocol_type_bin, \n",
    "                                       columns = ['is_'+x for x in trainDS.protocol_type.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding service **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS.service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "service_bin = pp.label_binarize(trainDS.service, \n",
    "                                classes = trainDS.service.unique())\n",
    "service_DataFrame = pd.DataFrame(service_bin, \n",
    "                                 columns = ['is_'+x for x in trainDS.service.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding flag **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS.flag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag_bin = pp.label_binarize(trainDS.flag, \n",
    "                                classes = trainDS.flag.unique())\n",
    "flag_DataFrame = pd.DataFrame(flag_bin, \n",
    "                                 columns = ['is_'+x for x in trainDS.flag.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Concatenating all de data set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS = pd.concat([trainDS, protocol_type_DataFrame, service_DataFrame, \n",
    "                     flag_DataFrame], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Selecting only numbered features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "continuousCols = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\"] + \\\n",
    "            [c for c in trainDS.columns if c.startswith(\"is_\")]\n",
    "trainDS = trainDS[continuousCols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Input Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = pp.MinMaxScaler().fit(trainDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_scaled = pd.DataFrame(scaler.transform(trainDS), columns=continuousCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = trainDS_scaled.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Total number of features: %d\" %n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_features, whiten=False)\n",
    "pca.fit(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accum explained variance ration\n",
    "pca.explained_variance_ratio_[0:].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(1 - pca.explained_variance_ratio_.cumsum(), drawstyle = 'steps-post')\n",
    "plt.title('PCA Reconstruction Error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_factors = sum(1-pca.explained_variance_ratio_[0:].cumsum() > 0.10)\n",
    "print \"Number of factors with 10% of reonstraction Error: \", n_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_factors)\n",
    "pca.fit(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Explained Variance Ratio\"\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_pca = pca.transform(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Labels categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = {'smurf': 'dos',\n",
    "              'neptune': 'dos',\n",
    "              'back': 'dos',\n",
    "              'teardrop': 'dos',\n",
    "              'pod': 'dos',\n",
    "              'land': 'dos',\n",
    "              'normal':'normal',\n",
    "              'satan': 'probe',\n",
    "              'ipsweep':'probe',\n",
    "              'portsweep':'probe',\n",
    "              'nmap': 'probe',\n",
    "              'warezclient':'r2l',\n",
    "              'guess_passwd':'r2l',\n",
    "              'warezmaster': 'r2l',\n",
    "              'imap': 'r2l',\n",
    "              'ftp_write': 'r2l',\n",
    "              'multihop': 'r2l',\n",
    "              'phf':'r2l',\n",
    "              'spy':'r2l',\n",
    "              'buffer_overflow': 'u2r',\n",
    "              'rootkit': 'u2r',\n",
    "              'loadmodule': 'u2r',\n",
    "              'perl': 'u2r'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataLabels['category_attack'] = pd.Categorical(dataLabels[\"class_attack\"].map(categories))\n",
    "dataLabels['is_attack'] = pd.Categorical([x == 'normal' for x in dataLabels[\"class_attack\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataLabels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Cluster metrics\n",
    "\n",
    "Two desirable objectives for any cluster assignment:\n",
    "* **homogeneity**: each cluster contains only members of a single class.\n",
    "* **completeness**: all members of a given class are assigned to the same cluster.\n",
    "\n",
    "The main cluster metrics are:\n",
    "\n",
    "* **Homogeneity Score**: A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.\n",
    "    * Bounded scores: 0.0 is as bad as it can be, 1.0 is a perfect score\n",
    "\n",
    "* **Completeness Score**: A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster.\n",
    "    * Bounded scores: 0.0 is as bad as it can be, 1.0 is a perfect score\n",
    "\n",
    "* **V measure Scores** : the harmonic mean between homogeneity and completeness: v = 2 * (homogeneity * completeness) / (homogeneity + completeness)\n",
    "    * Bounded scores: 0.0 is as bad as it can be, 1.0 is a perfect score\n",
    "\n",
    "* **Adjusted Rand index**: is a function that measures the similarity of the two assignments, ignoring permutations and with chance normalization\n",
    "    * Bounded range [-1, 1]: negative values are bad (independent labelings), similar clusterings have a positive ARI, 1.0 is the perfect match score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Parameters**: number of clusters\n",
    "* **Scalability**:\tVery large n_samples, medium n_clusters\n",
    "* **Usecase**:\tGeneral-purpose, even cluster size, flat geometry, not too many clusters\n",
    "* **Geometry (metric used)**: Distances between points\n",
    "\t\t \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Random centroid initialization (5 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_Clusters = 5\n",
    "random_K_means = KMeans(init='random', n_clusters = n_Clusters, n_init= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time random_K_means.fit(trainDS_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Cluster metrics\"\n",
    "print \"Homogeneity Score:\" , metrics.homogeneity_score(random_K_means.labels_, dataLabels.category_attack)\n",
    "print \"Completeness Score:\", metrics.completeness_score(random_K_means.labels_, dataLabels.category_attack)\n",
    "print \"V measure score:\", metrics.v_measure_score(random_K_means.labels_, dataLabels.category_attack)\n",
    "print \"Adjusted Rand Index:\", metrics.adjusted_rand_score(random_K_means.labels_, dataLabels.category_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results on PCA-reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the results on PCA-reduced data\n",
    "\n",
    "pca = PCA(n_components= 2, whiten=True)\n",
    "DS_projected = pca.fit_transform(trainDS_pca)\n",
    "\n",
    "n_Clusters = 5\n",
    "random_K_means_2 = KMeans(init='random', n_clusters = n_Clusters, n_init = 10)\n",
    "random_K_means_2.fit_predict(DS_projected);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = \"rgbcm\"\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 7) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "# Plot the clusters\n",
    "for i, color in zip(set(random_K_means_2.labels_), colors):\n",
    "    idx = np.where(random_K_means_2.labels_== i)\n",
    "    ax1.scatter(DS_projected[idx, 0], DS_projected[idx, 1], c=color, s = 10, label=i, alpha = 0.5, edgecolors='none')\n",
    "    # Plot the centroids as X\n",
    "    ax1.scatter(random_K_means_2.cluster_centers_[i, 0], random_K_means_2.cluster_centers_[i, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color=color, zorder=10)\n",
    "ax1.set_title('K-mean prediction - Random centroid initialization (5 clusters)')\n",
    "ax1.legend()\n",
    "\n",
    "#Plot the category values\n",
    "for i, color in zip(set(dataLabels.category_attack), colors):\n",
    "    idx = np.where(dataLabels.category_attack == i)\n",
    "    ax2.scatter(DS_projected[idx, 0], DS_projected[idx, 1], c=color, s = 10, label=i, alpha = 0.5, edgecolors='none')\n",
    "    \n",
    "ax2.set_title('Category Attacks (5 categories)')\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results on PCA-reduced data 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3, whiten=True)\n",
    "DS_projected = pca.fit_transform(trainDS_pca)\n",
    "\n",
    "n_Clusters = 5\n",
    "random_K_means_3 = KMeans(init='random', n_clusters = n_Clusters, n_init = 15)\n",
    "random_K_means_3.fit_predict(DS_projected);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "colors =  \"rgbcm\"\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Plot the clusters\n",
    "for i, color in zip(set(random_K_means_3.labels_), colors):\n",
    "    idx = np.where( random_K_means_3.labels_== i)\n",
    "    ax.scatter(DS_projected[idx, 0], DS_projected[idx, 1], DS_projected[idx, 2], c=color, label=i, s=50, alpha = 0.3, \n",
    "               edgecolors='none')\n",
    "    # Plot the centroids as X\n",
    "    ax.scatter(random_K_means_3.cluster_centers_[i, 0], random_K_means_3.cluster_centers_[i, 1], \n",
    "                random_K_means_3.cluster_centers_[i, 2], marker='x', linewidths=3, s = 150,\n",
    "                color=color, zorder=10)\n",
    "ax.set_title('K-mean prediction - Random centroid initialization (5 clusters)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1: \n",
    "Repeat the experiment with the cluster initialitation K-means++ and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 K-means++ centroid initialization (5 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Random centroid initialization (2 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_Clusters = 2\n",
    "random_K_means = KMeans(init='random', n_clusters = n_Clusters, n_init = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time random_K_means.fit(trainDS_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Cluster metrics\"\n",
    "print \"Homogeneity Score:\" , metrics.homogeneity_score(random_K_means.labels_, dataLabels.is_attack)\n",
    "print \"Completeness Score:\", metrics.completeness_score(random_K_means.labels_, dataLabels.is_attack)\n",
    "print \"V measure score:\", metrics.v_measure_score(random_K_means.labels_, dataLabels.is_attack)\n",
    "print \"Adjusted Rand Index:\", metrics.adjusted_rand_score(random_K_means.labels_, dataLabels.is_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results on PCA-reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 2, whiten=True)\n",
    "DS_projected = pca.fit_transform(trainDS_pca)\n",
    "\n",
    "n_Clusters = 2\n",
    "random_K_means_2 = KMeans(init='random', n_clusters = n_Clusters, n_init = 15)\n",
    "random_K_means_2.fit_predict(DS_projected);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = \"br\"\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 7) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "# Plot the clusters\n",
    "for i, color in zip(set(random_K_means_2.labels_), colors):\n",
    "    idx = np.where( random_K_means_2.labels_== i)\n",
    "    ax1.scatter(DS_projected[idx, 0], DS_projected[idx, 1], c=color, s = 10, label=i, alpha = 0.3, edgecolors='none')\n",
    "    # Plot the centroids as X\n",
    "    ax1.scatter(random_K_means_2.cluster_centers_[i, 0], random_K_means_2.cluster_centers_[i, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color=color, zorder=10)\n",
    "ax1.set_title('K-mean prediction - Random centroid initialization (2 clusters)')\n",
    "ax1.legend()\n",
    "\n",
    "#Plot the category values\n",
    "for i, color in zip(set(dataLabels.is_attack), colors):\n",
    "    idx = np.where(dataLabels.is_attack == i)\n",
    "    ax2.scatter(DS_projected[idx, 0], DS_projected[idx, 1], c=color, s = 10, label=i, alpha = 0.3, edgecolors='none')\n",
    "    \n",
    "ax2.set_title('Category Attacks (2 categories)')\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2: \n",
    "Repeat the experiment with the cluster initialitation K-means++ and compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 K-means++ centroid initialization (2 clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 Find the best number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getK_meansMesures(initArg = 'random', n_clusters = 2, labels = None, data = None):\n",
    "    model = KMeans(init=initArg, n_clusters = n_clusters, n_init = 10)\n",
    "    model.fit(data)\n",
    "    return [n_clusters,\n",
    "            metrics.homogeneity_score(model.labels_, labels), \n",
    "            metrics.completeness_score(model.labels_, labels), \n",
    "            metrics.v_measure_score(model.labels_, labels), \n",
    "            metrics.adjusted_rand_score(model.labels_, labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Attack (23 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = np.array([getK_meansMesures('random', n_Clusters, dataLabels.class_attack, trainDS_pca)\n",
    "                     for n_Clusters in range(2,24)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(measures[:,0], measures[:,1], label = 'Homogeneity')\n",
    "plt.plot(measures[:,0], measures[:,2], label = 'Completeness')\n",
    "plt.plot(measures[:,0], measures[:,3], label = 'V measure')\n",
    "plt.plot(measures[:,0], measures[:,4], label = 'Adjusted Rand')\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Cluster measures\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Attack (5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measures = np.array([getK_meansMesures('random', n_Clusters, dataLabels.category_attack, trainDS_pca)\n",
    "                     for n_Clusters in range(2,13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(measures[:,0], measures[:,1], label = 'Homogeneity')\n",
    "plt.plot(measures[:,0], measures[:,2], label = 'Completeness')\n",
    "plt.plot(measures[:,0], measures[:,3], label = 'V measure')\n",
    "plt.plot(measures[:,0], measures[:,4], label = 'Adjusted Rand')\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Cluster measures\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3: \n",
    "Find the best number of cluster to the attribute *is_attack* (2 categories) and compare the results with the others experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is Attack (2 categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm  density-based clustering algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Parameters**: \n",
    "    * *eps*: The maximum distance between two samples for them to be considered as in the same neighborhood\n",
    "    * *min_samples*: The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "* **Scalability**:\tVery large n_samples, medium n_clusters\n",
    "* **Usecase**:\tNon-flat geometry, uneven cluster sizes\n",
    "* **Geometry (metric used)**: Distances between nearest points\n",
    "\t\t \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN\tneighborhood size\tVery large n_samples, medium n_clusters\tNon-flat geometry, uneven cluster sizes\tDistances between nearest points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.5, min_samples=125).fit(trainDS_pca)\n",
    "n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)#outlayers are labeled like -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Cluster metrics\"\n",
    "print \"Number of clusters found:\", n_clusters_\n",
    "print \"Number of outlayers:\", sum(db.labels_==-1)\n",
    "print \"Homogeneity Score:\" , metrics.homogeneity_score(db.labels_, dataLabels.class_attack)\n",
    "print \"Completeness Score:\", metrics.completeness_score(db.labels_, dataLabels.class_attack)\n",
    "print \"V measure score:\", metrics.v_measure_score(db.labels_, dataLabels.class_attack)\n",
    "print \"Adjusted Rand Index:\", metrics.adjusted_rand_score(db.labels_, dataLabels.class_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results on PCA-reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 2, whiten=True)\n",
    "DS_projected = pca.fit_transform(trainDS_pca)\n",
    "\n",
    "db = DBSCAN(eps=0.5, min_samples=125).fit(DS_projected)\n",
    "n_clusters_ = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0) #outlayers are labeled like -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 7) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "unique_labels = set(db.labels_)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = 'k'\n",
    "\n",
    "    class_member_mask = (db.labels_ == k)\n",
    "\n",
    "    xy = DS_projected[class_member_mask & core_samples_mask]\n",
    "    ax1.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = DS_projected[class_member_mask & ~core_samples_mask]\n",
    "    ax1.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "ax1.set_title('Estimated clusters: %d & outlayers: %d' % (n_clusters_, sum(db.labels_==-1)))\n",
    "\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(set(dataLabels.category_attack))))\n",
    "for i, color in zip(set(dataLabels.category_attack), colors):\n",
    "    idx = np.where(dataLabels.category_attack == i)\n",
    "    ax2.scatter(DS_projected[idx, 0], DS_projected[idx, 1], c=color, s = 30, label=i, \n",
    "                alpha = 0.5, edgecolors='none')\n",
    "    \n",
    "ax2.set_title('Category Attacks (5 categories)')\n",
    "ax2.legend();\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 4: \n",
    "Repeat the experiment with *eps* = 1 and *min_samples* = 250 and compare the results with the last experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Find the best parameter *eps* (with min_samples = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDBSCANMesures(eps = 0.5, min_samples = 100, labels = None, data = None ):\n",
    "    model = DBSCAN(eps = eps, min_samples = min_samples)\n",
    "    model.fit(data)\n",
    "    n_clusters_ = len(set(model.labels_)) - (1 if -1 in model.labels_ else 0) #outlayers are labeled like -1\n",
    "    n_outlayers_ = sum(model.labels_==-1)\n",
    "    return [eps, min_samples,\n",
    "            metrics.homogeneity_score(model.labels_, labels), \n",
    "            metrics.completeness_score(model.labels_, labels), \n",
    "            metrics.v_measure_score(model.labels_, labels), \n",
    "            metrics.adjusted_rand_score(model.labels_, labels),\n",
    "            n_clusters_,\n",
    "            n_outlayers_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps_measures = np.array([getDBSCANMesures(eps = eps_, min_samples = 125 , labels = dataLabels.class_attack, data = trainDS_pca) \n",
    "            for eps_ in np.arange(0.25,1.26,0.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(eps_measures[:,0], eps_measures[:,2], label = 'Homogeneity')\n",
    "plt.plot(eps_measures[:,0], eps_measures[:,3], label = 'Completeness')\n",
    "plt.plot(eps_measures[:,0], eps_measures[:,4], label = 'V measure')\n",
    "plt.plot(eps_measures[:,0], eps_measures[:,5], label = 'Adjusted Rand')\n",
    "plt.legend()\n",
    "plt.ylim(0,1)\n",
    "plt.title(\"Cluster measures\")\n",
    "plt.xlabel(\"eps\")\n",
    "plt.ylabel(\"Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Find the best parameter *min_samples* (with eps = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_s_measures = np.array([getDBSCANMesures(eps = 0.75, min_samples = min_samples_ , labels = dataLabels.class_attack, data = trainDS_pca) \n",
    "            for min_samples_ in range(25,501,50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(min_s_measures[:,1], min_s_measures[:,2], label = 'Homogeneity')\n",
    "plt.plot(min_s_measures[:,1], min_s_measures[:,3], label = 'Completeness')\n",
    "plt.plot(min_s_measures[:,1], min_s_measures[:,4], label = 'V measure')\n",
    "plt.plot(min_s_measures[:,1], min_s_measures[:,5], label = 'Adjusted Rand')\n",
    "plt.legend()\n",
    "plt.title(\"Cluster measures\")\n",
    "plt.xlabel(\"min_sample\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
