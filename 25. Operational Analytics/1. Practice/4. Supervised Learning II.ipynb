{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD99 Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intrinsic attributes**\n",
    "\n",
    "These attributes are extracted from the headers' area of the network packets.\n",
    "\n",
    "Col|Feature name  | description |\ttype\n",
    "---|--------------|-------------|------------\n",
    "1  |duration \t  |length (number of seconds) of the connection |continuous\n",
    "2  |protocol_type |type of the protocol, e.g. tcp, udp, etc. |discrete\n",
    "3  |service \t  |network service on the destination, e.g., http, telnet, etc. |discrete\n",
    "4  |flag \t      |normal or error status of the connection. The possible status are this: SF, S0, S1, S2, S3, OTH, REJ, RSTO, RSTOS0, SH, RSTRH, SHR \t|discrete \n",
    "5  |src_bytes \t  |number of data bytes from source to destination \t|continuous\n",
    "6  |dst_bytes \t  |number of data bytes from destination to source \t|continuous\n",
    "7  |land \t      |1 if connection is from/to the same host/port; 0 otherwise \t|discrete\n",
    "8  |wrong_fragment|sum of bad checksum packets in a connection \t|continuous\n",
    "9  |urgent \t      |number of urgent packets. Urgent packets are packets with the urgent bit activated \t|continuous\n",
    "\n",
    "\n",
    "**Class attribute**\n",
    "\n",
    "The 42nd attribute is the ***class_attack*** attribute, it indicates which type of connections is each instance: normal or which attack. The values it can take are the following: *anomaly, dict, dict_simple, eject, eject-fail, ffb, ffb_clear, format, format_clear, format-fail, ftp-write, guest, imap, land, load_clear, loadmodule, multihop, perl_clear, perlmagic, phf, rootkit, spy, syslog, teardrop, warez, warezclient, warezmaster, pod, back, ip- sweep, neptune, nmap, portsweep, satan, smurf and normal*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Categories of class attribute **\n",
    "\n",
    "\n",
    "class_attack |Category\n",
    "-------|--------------\n",
    "smurf| dos\n",
    "neptune| dos\n",
    "back| dos\n",
    "teardrop| dos\n",
    "pod| dos\n",
    "land| dos\n",
    "normal|normal\n",
    "satan|probe\n",
    "ipsweep|probe\n",
    "portsweep|probe\n",
    "nmap|probe\n",
    "warezclient|r2l\n",
    "guess_passwd|r2l\n",
    "warezmaster|r2l\n",
    "imap|r2l\n",
    "ftp_write|r2l\n",
    "multihop|r2l\n",
    "phf|r2l\n",
    "spy|r2l\n",
    "buffer_overflow|u2r\n",
    "rootkit|u2r\n",
    "loadmodule|u2r\n",
    "perl|u2r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData = pd.read_csv('./data/KDD/KDDTrain+.txt', header=None, usecols=[0,1,2,3,4,5,6,7,8,41], \n",
    "                   dtype = {\"duration\": 'float64',\n",
    "                            \"protocol_type\": 'object',\n",
    "                            \"service\": 'object',\n",
    "                            \"flag\": 'object',\n",
    "                            \"src_bytes\": 'float64',\n",
    "                            \"dst_bytes\": 'float64',\n",
    "                            \"land\": 'object',\n",
    "                            \"wrong_fragment\": 'float64',\n",
    "                            \"urgent\": 'float64',\n",
    "                            \"class_attack\": 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData.columns=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "                 \"wrong_fragment\",\"urgent\", \"class_attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData.protocol_type = trainingData.protocol_type.astype('category')\n",
    "trainingData.service = trainingData.service.astype('category')\n",
    "trainingData.flag = trainingData.flag.astype('category')\n",
    "trainingData.class_attack = trainingData.class_attack.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS = trainingData[['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', \n",
    "         'wrong_fragment', 'urgent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainLabels = pd.DataFrame(trainingData['class_attack'], dtype='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainLabels[\"is_normal\"] = np.array(trainLabels.class_attack == 'normal',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainLabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loading Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData = pd.read_csv('./data/KDD/KDDTest+.txt', header=None, usecols=[0,1,2,3,4,5,6,7,8,41],\n",
    "                   dtype = {\"duration\": 'float64',\n",
    "                            \"protocol_type\": 'object',\n",
    "                            \"service\": 'object',\n",
    "                            \"flag\": 'object',\n",
    "                            \"src_bytes\": 'float64',\n",
    "                            \"dst_bytes\": 'float64',\n",
    "                            \"land\": 'object',\n",
    "                            \"wrong_fragment\": 'float64',\n",
    "                            \"urgent\": 'float64',\n",
    "                            \"class_attack\": 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData.columns=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "                 \"wrong_fragment\",\"urgent\", \"class_attack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData.protocol_type = testData.protocol_type.astype('category')\n",
    "testData.service = testData.service.astype('category')\n",
    "testData.flag = testData.flag.astype('category')\n",
    "testData.class_attack = testData.class_attack.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS = testData[['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', \n",
    "         'wrong_fragment', 'urgent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLabels = pd.DataFrame(testData['class_attack'], dtype='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLabels[\"is_normal\"] = np.array(testLabels.class_attack == 'normal',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attack_class = list(set(trainLabels.class_attack.unique().tolist()+\n",
    "                               testLabels.class_attack.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print attack_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb_train_attack_class = pp.LabelBinarizer()\n",
    "lb_train_attack_class.fit(attack_class)\n",
    "lb_train_attack_class.transform(trainLabels.class_attack).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb_train_attack_class.classes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_attack_class_bin = lb_train_attack_class.transform(trainLabels.class_attack)\n",
    "\n",
    "##pp.label_binarize(trainLabels.class_attack, \n",
    "                        #              classes = attack_class)\n",
    "trainLabels_encoded = pd.DataFrame(train_attack_class_bin, \n",
    "                                       columns = ['is_'+x for x in attack_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_attack_class_bin = lb_train_attack_class.transform(testLabels.class_attack)\n",
    "#pp.label_binarize(testLabels.class_attack, \n",
    "#                                      classes = attack_class)\n",
    "testLabels_encoded = pd.DataFrame(test_attack_class_bin, \n",
    "                                       columns = ['is_'+x for x in attack_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding protocol_type **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protocol_type_class = list(set(trainDS.protocol_type.unique().tolist()+\n",
    "                               testDS.protocol_type.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print protocol_type_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_protocol_type_bin = pp.label_binarize(trainDS.protocol_type, \n",
    "                                      classes = protocol_type_class)\n",
    "train_protocol_type_DataFrame = pd.DataFrame(train_protocol_type_bin, \n",
    "                                       columns = ['is_'+x for x in protocol_type_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_protocol_type_bin = pp.label_binarize(testDS.protocol_type, \n",
    "                                      classes = protocol_type_class)\n",
    "test_protocol_type_DataFrame = pd.DataFrame(test_protocol_type_bin, \n",
    "                                       columns = ['is_'+x for x in protocol_type_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding service **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "service_class = list(set(trainDS.service.unique().tolist()+\n",
    "                               testDS.service.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print service_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_service_bin = pp.label_binarize(trainDS.service, \n",
    "                                      classes = service_class)\n",
    "train_service_DataFrame = pd.DataFrame(train_service_bin, \n",
    "                                       columns = ['is_'+x for x in service_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_service_bin = pp.label_binarize(testDS.service, \n",
    "                                     classes = service_class)\n",
    "test_service_DataFrame = pd.DataFrame(test_service_bin, \n",
    "                                      columns = ['is_'+x for x in service_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Encoding flag **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag_class = list(set(trainDS.flag.unique().tolist()+\n",
    "                               testDS.flag.unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print flag_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_flag_bin = pp.label_binarize(trainDS.flag, \n",
    "                                    classes = flag_class)\n",
    "train_flag_DataFrame = pd.DataFrame(train_flag_bin, \n",
    "                                 columns = ['is_'+x for x in flag_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_flag_bin = pp.label_binarize(testDS.flag, \n",
    "                                  classes = flag_class)\n",
    "test_flag_DataFrame = pd.DataFrame(test_flag_bin, \n",
    "                                   columns = ['is_'+x for x in flag_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Concatenating all de data set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_encoded = pd.concat([trainDS, train_protocol_type_DataFrame, train_service_DataFrame, \n",
    "                     train_flag_DataFrame], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS_encoded = pd.concat([testDS, test_protocol_type_DataFrame, test_service_DataFrame, \n",
    "                     test_flag_DataFrame], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Selecting only numbered features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "continuousCols_train = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\"] + \\\n",
    "            [c for c in trainDS_encoded.columns if c.startswith(\"is_\")]\n",
    "trainDS_encoded = pd.DataFrame(trainDS_encoded[continuousCols_train], dtype='float64')\n",
    "print trainDS_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "continuousCols_test = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\"] + \\\n",
    "            [c for c in testDS_encoded.columns if c.startswith(\"is_\")]\n",
    "testDS_encoded = pd.DataFrame(testDS_encoded[continuousCols_test], dtype='float64')\n",
    "print testDS_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Input Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = pp.MinMaxScaler().fit(trainDS_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_scaled = pd.DataFrame(scaler.transform(trainDS_encoded), columns =  continuousCols_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: Using the scaler from *trainDS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS_scaled = pd.DataFrame(scaler.transform(testDS_encoded), columns =  continuousCols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = trainDS_scaled.columns.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Total number of features: %d\" %n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_features, whiten=False)\n",
    "pca.fit(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#accum explained variance ration\n",
    "pca.explained_variance_ratio_[0:].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(1 - pca.explained_variance_ratio_.cumsum(), drawstyle = 'steps-post')\n",
    "plt.title('PCA Reconstruction Error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_factors = sum(1-pca.explained_variance_ratio_[0:].cumsum() > 0.10)\n",
    "print \"Number of factors with 10% of reonstraction Error: \", n_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_factors)\n",
    "pca.fit(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Explained Variance Ratio\"\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDS_pca = pca.transform(trainDS_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: Using the pca from *trainDS_scaled* to *testDS_scaled*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDS_pca = pca.transform(testDS_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Parameters**: \n",
    "   * *C* : Penalty parameter C of the error term\n",
    "   * *gamma* : Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.\n",
    "   * *degree* : Degree of the polynomial kernel function (‘poly’). Ignored by all other kernels.\n",
    "   * *kernel* : ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable \n",
    "* **Usecase**:\tClasification\n",
    "* **Complexity**: The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data.\n",
    "\t\t \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSVMMesures(C = 1, kernel = 'rbf', max_iter = 1e3, tol = 1e-3,\n",
    "                  train_size = None, n_experiments = 1,\n",
    "                  train_labels = None, train_data = None, gamma = 0.0, degree = 3, order = None):\n",
    "    \n",
    "    \n",
    "    model = SVC(C = C, gamma = gamma, kernel = kernel, degree = degree, tol = tol, max_iter = max_iter)\n",
    "    \n",
    "    test_size = train_size * 0.2\n",
    "    sss = StratifiedShuffleSplit(train_labels, n_iter = n_experiments, \n",
    "                                 train_size = train_size, \n",
    "                                 test_size = test_size,\n",
    "                                 random_state = np.random.random_integers(0,100000))\n",
    "    \n",
    "    modelsFitted = [model.fit(train_data[train_ix, :], train_labels[train_ix])\n",
    "                    for train_ix, test_ix in sss]\n",
    "    \n",
    "    scores = [(m.score(train_data[train_ix, :], train_labels[train_ix]),\n",
    "              m.score(train_data[test_ix, :], train_labels[test_ix]))\n",
    "              for m, (train_ix, test_ix) in zip(modelsFitted, sss)]\n",
    "    \n",
    "    meanScores = np.mean(scores, axis = 0)\n",
    "    maxScores = np.max(scores, axis = 0)\n",
    "    minScores = np.min(scores, axis = 0)\n",
    "    \n",
    "    return [model.C,\n",
    "            model.kernel,\n",
    "            model.max_iter,\n",
    "            model.tol,\n",
    "            train_size,\n",
    "            meanScores[0],# mean E_in\n",
    "            maxScores[0], # max E_in\n",
    "            minScores[0], # min E_in\n",
    "            meanScores[1],# mean E_out\n",
    "            maxScores[1], # max E_out\n",
    "            minScores[1], # min E_out\n",
    "            order,\n",
    "            model.gamma,\n",
    "            model.degree,\n",
    "            model] #model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 SVM: Kernel linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmModel = SVC(C=1, kernel='linear', cache_size= 200, tol = 1e-3, max_iter = -1)\n",
    "%time svmModel.fit(trainDS_pca, trainLabels.is_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean accuracy on the given train data and labels: \"\n",
    "%time svmModel.score(trainDS_pca, trainLabels.is_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean accuracy on the given test data and labels: \"\n",
    "%time svmModel.score(testDS_pca, testLabels.is_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.1 Finding out the Training Set Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING: IT TAKES 4 MIN APROX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "SVM_Linear_measures_size = np.array([getSVMMesures(C = 1, kernel = 'linear', train_size = n*0.1, \n",
    "                                                   n_experiments = 10, train_labels = trainLabels.is_normal, \n",
    "                                                   train_data = trainDS_pca) \n",
    "                                     for n in range(1,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 4)\n",
    "ax1.grid()\n",
    "ax1.set_title('SVM: select the size of training Set (kernel = linear). E_in')\n",
    "ax1.set_xlabel(\"% of Train Data Set\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.65,0.97);\n",
    "\n",
    "\n",
    "ax2.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_Linear_measures_size[:,4], SVM_Linear_measures_size[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 4)\n",
    "ax2.grid()\n",
    "ax2.set_title(\"SVM: select the size of training Set (kernel = linear). E_out\")\n",
    "ax2.set_xlabel(\"% of Train Data Set\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.65,0.97);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Percentage of training set* ** =  10% **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.2 Finding out the best regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = [ 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "SVM_Linear_measures_C = np.array([getSVMMesures(C = c, kernel = 'linear', \n",
    "                                                    train_size = train_size, n_experiments = 6, \n",
    "                                                    train_labels = trainLabels.is_normal, \n",
    "                                                    train_data = trainDS_pca) \n",
    "                                    for c in Cs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 3)\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.grid()\n",
    "ax1.set_title('SVM: Regularization paramenter (kernel = linear). E_in')\n",
    "ax1.set_xlabel(\"C: Regularization Parameter\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.4, 1);\n",
    "\n",
    "ax2.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_Linear_measures_C[:,0], SVM_Linear_measures_C[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 3)\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.grid()\n",
    "ax2.set_title(\"SVM: Regularization parameter (kernel = linear). E_out\")\n",
    "ax2.set_xlabel(\"C: Regularization Parameter\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.4, 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Penalty parameter C of the error term* **C =  1e-1 **\n",
    "\n",
    "New model with C = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "SVM_Linear_measures = np.array([getSVMMesures(C = 1e-1, kernel = 'linear', \n",
    "                                              train_size = train_size, \n",
    "                                              n_experiments = 6, \n",
    "                                              train_labels = trainLabels.is_normal, \n",
    "                                              train_data = trainDS_pca, order = n) \n",
    "                                for n in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 3)\n",
    "ax1.grid()\n",
    "ax1.set_title('SVM: (kernel = linear, C = 1e-1). E_in')\n",
    "ax1.set_xlabel(\"Experimenet Number\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.9, 1);\n",
    "\n",
    "ax2.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_Linear_measures[:,11], SVM_Linear_measures[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 3)\n",
    "ax2.grid()\n",
    "ax2.set_title(\"SVM (kernel = linear, C = 1e-1). E_out\")\n",
    "ax2.set_xlabel(\"Experimenet Number\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.9, 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.3 Saving the best SVM Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmModel = SVM_Linear_measures[8][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mkdir './models/SVM_Linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(svmModel, './models/SVM_Linear/SVM_linear.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 SVM: Radius Basis Function (RBF) kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING: IT TAKES 17 MIN APROX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmModel = SVC(C=1, kernel='rbf')\n",
    "%time svmModel.fit(trainDS_pca, trainLabels.is_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean accuracy on the given train data and labels: \"\n",
    "svmModel.score(trainDS_pca, trainLabels.is_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Mean accuracy on the given test data and labels: \"\n",
    "svmModel.score(testDS_pca, testLabels.is_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = svmModel.predict(testDS_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Confusion Matrix\"\n",
    "metrics.confusion_matrix(testLabels.is_normal, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.1 Finding out the Training Set Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "SVM_RBF_measures_size = np.array([getSVMMesures(C = 1, kernel = 'rbf', \n",
    "                                                train_size = n*0.1, n_experiments = 6, \n",
    "                                                train_labels = trainLabels.is_normal, \n",
    "                                                train_data = trainDS_pca) \n",
    "                                  for n in range(1,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 1)\n",
    "ax1.grid()\n",
    "ax1.set_title('SVM: select the size of training Set (kernel = rbf). E_in')\n",
    "ax1.set_xlabel(\"% of Train Data Set\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.7,0.97);\n",
    "\n",
    "\n",
    "ax2.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_RBF_measures_size[:,4], SVM_RBF_measures_size[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 1)\n",
    "ax2.grid()\n",
    "ax2.set_title(\"SVM: select the size of training Set (kernel = rbf). E_out\")\n",
    "ax2.set_xlabel(\"% of Train Data Set\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.7,0.97);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Percentage of training set* ** =  10% **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.2 Finding out the best regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = [ 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "SVM_RBF_measures_C = np.array([getSVMMesures(C = c, kernel = 'rbf', \n",
    "                                             train_size = train_size, n_experiments = 6, \n",
    "                                             train_labels = trainLabels.is_normal, \n",
    "                                             train_data = trainDS_pca) \n",
    "                               for c in Cs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 3)\n",
    "ax1.grid()\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.set_title('SVM: Regularization parameter (kernel = rbf). E_in')\n",
    "ax1.set_xlabel(\"C: Regularization Parameter\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.9,1);\n",
    "\n",
    "\n",
    "ax2.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_RBF_measures_C[:,0], SVM_RBF_measures_C[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 3)\n",
    "ax2.grid()\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_title(\"SVM: Regularization parameter (kernel = rbf). E_out\")\n",
    "ax2.set_xlabel(\"C: Regularization Parameter\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.9,1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Penalty parameter C of the error term* **C =  10 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.3 Finding out the best *gamma* with regularization parameter C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gammas = [ 1e5, 1e4, 1e3, 1e2, 1e1, 1e0, 1e-1, 1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "SVM_RBF_measures_gamma = np.array([getSVMMesures(C = 10, gamma = g, kernel = 'rbf', \n",
    "                                             train_size = train_size, n_experiments = 6, \n",
    "                                             train_labels = trainLabels.is_normal, \n",
    "                                             train_data = trainDS_pca) \n",
    "                               for g in gammas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 3)\n",
    "ax1.grid()\n",
    "ax1.set_xscale(\"log\")\n",
    "ax1.set_title('SVM: gamma (kernel = rbf). E_in')\n",
    "ax1.set_xlabel(\"Kernel coefficient gamma\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.925,0.975);\n",
    "\n",
    "\n",
    "ax2.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_RBF_measures_gamma[:,12], SVM_RBF_measures_gamma[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 3)\n",
    "ax2.grid()\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.set_title(\"SVM: gamma (kernel = rbf). E_out\")\n",
    "ax2.set_xlabel(\"Kernel coefficient gamma\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.925,0.975);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Penalty parameter C of the error term* **C =  10 **\n",
    "\n",
    "*Kernel Coefficient* **gamma = 1e2 **\n",
    "\n",
    "New model with C = 10 and gamma = 1e3 with the 10% of the training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "SVM_RBF_measures = np.array([getSVMMesures(C = 10, gamma= 1e2, kernel = 'rbf', \n",
    "                                           train_size = train_size, \n",
    "                                           n_experiments = 6, \n",
    "                                           train_labels = trainLabels.is_normal, \n",
    "                                           train_data = trainDS_pca, order = n) \n",
    "                            for n in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(20, 10) )\n",
    "ax1, ax2 = axes.ravel()\n",
    "\n",
    "ax1.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,5], label = 'mean Score in', c = 'b')\n",
    "ax1.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,6], label = 'max Score in', c = 'g')\n",
    "ax1.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,7], label = 'min Score in', c = 'r')\n",
    "ax1.legend(loc = 3)\n",
    "ax1.grid()\n",
    "ax1.set_title('SVM: (kernel = rbf, C = 10, gamma = 1e2). E_in')\n",
    "ax1.set_xlabel(\"Experimenet Number\")\n",
    "ax1.set_ylabel(\"Scores In\")\n",
    "ax1.set_ylim(0.925, 0.975);\n",
    "\n",
    "ax2.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,8], label = 'mean Score out', c = 'b')\n",
    "ax2.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,9], label = 'max Score out', c = 'g')\n",
    "ax2.plot(SVM_RBF_measures[:,11], SVM_RBF_measures[:,10], label = 'min Score out', c = 'r')\n",
    "ax2.legend(loc = 3)\n",
    "ax2.grid()\n",
    "ax2.set_title(\"SVM (kernel = rbf, C = 10, gamma = 1e2). E_out\")\n",
    "ax2.set_xlabel(\"Experimenet Number\")\n",
    "ax2.set_ylabel(\"Scores Out\")\n",
    "ax2.set_ylim(0.925, 0.975);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.4 Saving the best SVM Radius Basis Fuction (RBF) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%mkdir './models/SVM_RBF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmModel = SVM_RBF_measures[8][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(svmModel, './models/SVM_RBF/SVM_RBF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "Find the best parameters to SVC with Polynomial Kernel:\n",
    "* Training size\n",
    "* Degree\n",
    "* Regularization paramenter (C)\n",
    "* Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
