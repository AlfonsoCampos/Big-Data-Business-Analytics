{
 "metadata": {
  "name": "",
  "signature": "sha256:616fd21d3705866d19dd74d057d175ea0100aad9c12d2b7c94a4c14e6bffe2bb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#NLTK"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "showing info http://nltk.github.com/nltk_data/\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "sentence = \"At eight o'clock on Thursday morning, Arthur didn't feel very good.\"\n",
      "tokens = nltk.word_tokenize(sentence)\n",
      "print \"\\ntokens:\",tokens\n",
      "tagged = nltk.pos_tag(tokens)\n",
      "print \"\\ntagged:\",tagged\n",
      "\n",
      "#https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "tokens: ['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', ',', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
        "\n",
        "tagged: [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), (',', ','), ('Arthur', 'NNP'), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "from nltk.book import *\n",
      "text1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<Text: Moby Dick by Herman Melville 1851>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import cess_esp\n",
      "\n",
      "sents = cess_esp.tagged_sents()\n",
      "\n",
      "training = []\n",
      "test = []\n",
      "for i in range(len(sents)):\n",
      "    if i % 10:\n",
      "        training.append(sents[i])\n",
      "    else:\n",
      "        test.append(sents[i])\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "from nltk import UnigramTagger, BigramTagger, TrigramTagger\n",
      "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
      "\n",
      "unigram_tagger = UnigramTagger(training)\n",
      "bigram_tagger = BigramTagger(training, backoff=unigram_tagger) # uses unigram tagger in case it can't tag a word\n",
      "trigram_tagger = TrigramTagger(training, backoff=unigram_tagger)\n",
      "hmm_tagger = HiddenMarkovModelTagger.train(training)\n",
      "\n",
      "\n",
      "print 'UnigramTagger: %.1f %%' % (unigram_tagger.evaluate(test) * 100)\n",
      "print 'BigramTagger: %.1f %%' % (bigram_tagger.evaluate(test) * 100)\n",
      "print 'TrigramTagger: %.1f %%' % (trigram_tagger.evaluate(test) * 100)\n",
      "print 'HMM: %.1f %%' % (hmm_tagger.evaluate(test) * 100)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "UnigramTagger: 87.6 %\n",
        "BigramTagger: 89.4 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "TrigramTagger: 89.0 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "HMM: 89.9 %"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sents[1]\n",
      "print test[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Una', u'di0fs0'), (u'portavoz', u'nccs000'), (u'de', u'sps00'), (u'EDF', u'np00000'), (u'explic\\xf3', u'vmis3s0'), (u'a', u'sps00'), (u'EFE', u'np00000'), (u'que', u'cs'), (u'el', u'da0ms0'), (u'proyecto', u'ncms000'), (u'para', u'sps00'), (u'la', u'da0fs0'), (u'construcci\\xf3n', u'ncfs000'), (u'de', u'sps00'), (u'Altamira_2', u'np00000'), (u',', u'Fc'), (u'al', u'spcms'), (u'norte', u'ncms000'), (u'de', u'sps00'), (u'Tampico', u'np00000'), (u',', u'Fc'), (u'prev\\xe9', u'vmm02s0'), (u'la', u'da0fs0'), (u'utilizaci\\xf3n', u'ncfs000'), (u'de', u'sps00'), (u'gas', u'ncms000'), (u'natural', u'aq0cs0'), (u'como', u'cs'), (u'combustible', u'ncms000'), (u'principal', u'aq0cs0'), (u'en', u'sps00'), (u'una', u'di0fs0'), (u'central', u'ncfs000'), (u'de', u'sps00'), (u'ciclo', u'ncms000'), (u'combinado', u'aq0msp'), (u'que', u'pr0cn000'), (u'debe', u'vmip3s0'), (u'empezar', u'vmn0000'), (u'a', u'sps00'), (u'funcionar', u'vmn0000'), (u'en', u'sps00'), (u'mayo_del_2002', u'W'), (u'.', u'Fp')]\n",
        "[(u'*0*', u'sn.e-SUJ'), (u'Destac\\xf3', u'vmis3s0'), (u'que', u'cs'), (u'\"', u'Fe'), (u'por_fin', u'rg'), (u'\"', u'Fe'), (u'el', u'da0ms0'), (u'PP', u'np0000o'), (u'ha', u'vaip3s0'), (u'ganado', u'vmp00sm'), (u'en', u'sps00'), (u'la', u'da0fs0'), (u'circunscripci\\xf3n', u'ncfs000'), (u'de', u'sps00'), (u'M\\xe1laga', u'np0000l'), (u'tanto', u'rg'), (u'en', u'sps00'), (u'las', u'da0fp0'), (u'elecciones', u'ncfp000'), (u'generales', u'aq0cp0'), (u'como', u'cs'), (u'en', u'sps00'), (u'las', u'da0fp0'), (u'auton\\xf3micas', u'aq0fp0'), (u'y', u'cc'), (u'en', u'sps00'), (u'el', u'da0ms0'), (u'Senado', u'np0000o'), (u',', u'Fc'), (u'hecho', u'ncms000'), (u'que', u'pr0cn000'), (u'*0*', u'sn.e-SUJ'), (u'achac\\xf3', u'vmis3s0'), (u'entre', u'sps00'), (u'otros', u'di0mp0'), (u'factores', u'ncmp000'), (u'\"', u'Fe'), (u'al', u'spcms'), (u'trabajo', u'ncms000'), (u'de', u'sps00'), (u'los', u'da0mp0'), (u'alcaldes', u'ncmp000'), (u',', u'Fc'), (u'dando', u'vmg0000'), (u'ejemplo', u'ncms000'), (u'\"', u'Fe'), (u'.', u'Fp')]\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "sentence = \"Los perros son tontos\"\n",
      "tokens = nltk.word_tokenize(sentence)\n",
      "print \"\\ntokens:\",tokens\n",
      "tagged = nltk.pos_tag(tokens)\n",
      "print \"\\ntaggedEnglish:\",tagged\n",
      "tagged = hmm_tagger.tag(tokens)\n",
      "print \"\\ntaggedHMM:\",tagged\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "tokens: ['Los', 'perros', 'son', 'tontos']\n",
        "\n",
        "taggedEnglish: [('Los', 'NNP'), ('perros', 'NNS'), ('son', 'NN'), ('tontos', 'NNS')]\n",
        "\n",
        "taggedHMM: [('Los', u'da0mp0'), ('perros', u'ncmp000'), ('son', u'vsip3p0'), ('tontos', u'aq0cp0')]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sents[1],\"\\n\"\n",
      "print \"\\nsents contiene \",len(sents),\"frases\"\n",
      "for i in range(len(sents[1])):\n",
      "    print sents[1][i][0],sents[1][i][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Una', u'di0fs0'), (u'portavoz', u'nccs000'), (u'de', u'sps00'), (u'EDF', u'np00000'), (u'explic\\xf3', u'vmis3s0'), (u'a', u'sps00'), (u'EFE', u'np00000'), (u'que', u'cs'), (u'el', u'da0ms0'), (u'proyecto', u'ncms000'), (u'para', u'sps00'), (u'la', u'da0fs0'), (u'construcci\\xf3n', u'ncfs000'), (u'de', u'sps00'), (u'Altamira_2', u'np00000'), (u',', u'Fc'), (u'al', u'spcms'), (u'norte', u'ncms000'), (u'de', u'sps00'), (u'Tampico', u'np00000'), (u',', u'Fc'), (u'prev\\xe9', u'vmm02s0'), (u'la', u'da0fs0'), (u'utilizaci\\xf3n', u'ncfs000'), (u'de', u'sps00'), (u'gas', u'ncms000'), (u'natural', u'aq0cs0'), (u'como', u'cs'), (u'combustible', u'ncms000'), (u'principal', u'aq0cs0'), (u'en', u'sps00'), (u'una', u'di0fs0'), (u'central', u'ncfs000'), (u'de', u'sps00'), (u'ciclo', u'ncms000'), (u'combinado', u'aq0msp'), (u'que', u'pr0cn000'), (u'debe', u'vmip3s0'), (u'empezar', u'vmn0000'), (u'a', u'sps00'), (u'funcionar', u'vmn0000'), (u'en', u'sps00'), (u'mayo_del_2002', u'W'), (u'.', u'Fp')] \n",
        "\n",
        "\n",
        "sents contiene  6030 frases\n",
        "Una di0fs0\n",
        "portavoz nccs000\n",
        "de sps00\n",
        "EDF np00000\n",
        "explic\u00f3 vmis3s0\n",
        "a sps00\n",
        "EFE np00000\n",
        "que cs\n",
        "el da0ms0\n",
        "proyecto ncms000\n",
        "para sps00\n",
        "la da0fs0\n",
        "construcci\u00f3n ncfs000\n",
        "de sps00\n",
        "Altamira_2 np00000\n",
        ", Fc\n",
        "al spcms\n",
        "norte ncms000\n",
        "de sps00\n",
        "Tampico np00000\n",
        ", Fc\n",
        "prev\u00e9 vmm02s0\n",
        "la da0fs0\n",
        "utilizaci\u00f3n ncfs000\n",
        "de sps00\n",
        "gas ncms000\n",
        "natural aq0cs0\n",
        "como cs\n",
        "combustible ncms000\n",
        "principal aq0cs0\n",
        "en sps00\n",
        "una di0fs0\n",
        "central ncfs000\n",
        "de sps00\n",
        "ciclo ncms000\n",
        "combinado aq0msp\n",
        "que pr0cn000\n",
        "debe vmip3s0\n",
        "empezar vmn0000\n",
        "a sps00\n",
        "funcionar vmn0000\n",
        "en sps00\n",
        "mayo_del_2002 W\n",
        ". Fp\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n\",text2\n",
      "print \"\\n\",text2.count(\"monstrous\")\n",
      "print\n",
      "text2.concordance(\"monstrous\")\n",
      "print\n",
      "text1.similar(\"monstrous\",10)\n",
      "print\n",
      "text2.concordance(\"curious\")\n",
      "print\n",
      "text2.concordance(\"singular\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<Text: Sense and Sensibility by Jane Austen 1811>\n",
        "\n",
        "11\n",
        "\n",
        "Displaying 11 of 11 matches:\n",
        ". \" Now , Palmer , you shall see a monstrous pretty girl .\" He immediately went\n",
        "your sister is to marry him . I am monstrous glad of it , for then I shall have\n",
        "ou may tell your sister . She is a monstrous lucky girl to get him , upon my ho\n",
        "k how you will like them . Lucy is monstrous pretty , and so good humoured and \n",
        " Jennings , \" I am sure I shall be monstrous glad of Miss Marianne ' s company \n",
        " usual noisy cheerfulness , \" I am monstrous glad to see you -- sorry I could n\n",
        "t however , as it turns out , I am monstrous glad there was never any thing in \n",
        "so scornfully ! for they say he is monstrous fond of her , as well he may . I s\n",
        "possible that she should .\" \" I am monstrous glad of it . Good gracious ! I hav\n",
        "thing of the kind . So then he was monstrous happy , and talked on some time ab\n",
        "e very genteel people . He makes a monstrous deal of money , and they keep thei\n",
        "\n",
        "imperial subtly impalpable pitiable curious abundant perilous\n",
        "trustworthy untoward singular"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Displaying 1 of 1 matches:\n",
        " to have you think me impertinently curious . I am sure I would rather do any t\n",
        "\n",
        "No matches\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "#import nltk.book.text1\n",
      "print type(text1)\n",
      "print text1\n",
      "print len(set(word.lower() for word in text1 if word.isalpha()))\n",
      "\n",
      "l = [word.lower() for word in text1 if word.isalpha()]\n",
      "print l[0]\n",
      "print l[1]\n",
      "print l[100]\n",
      "\n",
      "l = list(word.lower() for word in text1 if word.isalpha())\n",
      "print l[:100]\n",
      "\n",
      "print \"Hola\\n\"\n",
      "print(word.lower() for word in text1 if not word.isalpha())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'nltk.text.Text'>\n",
        "<Text: Moby Dick by Herman Melville 1851>\n",
        "16948"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "moby"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "dick\n",
        "through\n",
        "[u'moby', u'dick', u'by', u'herman', u'melville', u'etymology', u'supplied', u'by', u'a', u'late', u'consumptive', u'usher', u'to', u'a', u'grammar', u'school', u'the', u'pale', u'usher', u'threadbare', u'in', u'coat', u'heart', u'body', u'and', u'brain', u'i', u'see', u'him', u'now', u'he', u'was', u'ever', u'dusting', u'his', u'old', u'lexicons', u'and', u'grammars', u'with', u'a', u'queer', u'handkerchief', u'mockingly', u'embellished', u'with', u'all', u'the', u'gay', u'flags', u'of', u'all', u'the', u'known', u'nations', u'of', u'the', u'world', u'he', u'loved', u'to', u'dust', u'his', u'old', u'grammars', u'it', u'somehow', u'mildly', u'reminded', u'him', u'of', u'his', u'mortality', u'while', u'you', u'take', u'in', u'hand', u'to', u'school', u'others', u'and', u'to', u'teach', u'them', u'by', u'what', u'name', u'a', u'whale', u'fish', u'is', u'to', u'be', u'called', u'in', u'our', u'tongue', u'leaving', u'out']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Hola\n",
        "\n",
        "<generator object <genexpr> at 0x7fb39fa15500>\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "print text1\n",
      "\n",
      "freq = FreqDist(text1)\n",
      "print(freq)\n",
      "print type(freq)\n",
      "print freq.items()[0:10]\n",
      "freq.hapaxes()\n",
      "\n",
      "text = \"Red lorry, yellow lorry, red lorry, yellow lorry.\"\n",
      "print text\n",
      "words = re.findall(\"[a-z]+\",text,re.IGNORECASE)\n",
      "print words\n",
      "fdist = nltk.FreqDist(words)\n",
      "print sorted(fdist) #sorted convierte en list un objeto fdist\n",
      "\n",
      "for key in fdist:\n",
      "    print key,\":\",fdist[key]\n",
      "\n",
      "\n",
      "#collocations(text1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Text: Moby Dick by Herman Melville 1851>\n",
        "<FreqDist with 19317 samples and 260819 outcomes>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<class 'nltk.probability.FreqDist'>\n",
        "[(u'funereal', 1), (u'unscientific', 1), (u'divinely', 2), (u'foul', 11), (u'four', 74), (u'gag', 2), (u'prefix', 1), (u'woods', 9), (u'clotted', 2), (u'Duck', 2)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Red lorry, yellow lorry, red lorry, yellow lorry.\n",
        "['Red', 'lorry', 'yellow', 'lorry', 'red', 'lorry', 'yellow', 'lorry']\n",
        "['Red', 'lorry', 'red', 'yellow']\n",
        "yellow : 2\n",
        "lorry : 4\n",
        "Red : 1\n",
        "red : 1\n"
       ]
      }
     ],
     "prompt_number": 141
    }
   ],
   "metadata": {}
  }
 ]
}