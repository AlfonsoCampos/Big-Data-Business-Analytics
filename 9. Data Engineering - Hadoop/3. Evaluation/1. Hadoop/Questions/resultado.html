<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="es" xml:lang="es" xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="stylesheet" type="text/css" href="base.css" />
<link rel="stylesheet" type="text/css" href="content.css" />
<link rel="stylesheet" type="text/css" href="nav.css" />
<meta http-equiv="content-type" content="text/html;  charset=utf-8" />
<title>Resultado </title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<meta http-equiv="content-language" content="es" />
<meta name="generator" content="eXeLearning 2.0.1 - exelearning.net" />
<script type="text/javascript" src="exe_jquery.js"></script>
<script type="text/javascript">$exe_i18n={show:"Mostrar",hide:"Ocultar",showFeedback:"Mostrar retroalimentación",hideFeedback:"Ocultar retroalimentación",correct:"Correcto",incorrect:"Incorrecto",menu:"Menú"}</script>
<script type="text/javascript" src="common.js"></script>
</head>
<body class="exe-web-site"><script type="text/javascript">document.body.className+=" js"</script>
<div id="content">
<p id="skipNav"><a href="#main" class="sr-av">Saltar la navegación</a></p>
<div id="emptyHeader"></div>
<div id="siteNav">
<ul>
   <li><a href="index.html" class="daddy main-node">Hadoop</a></li>
   <li><a href="conceptos_bsicos_y_definiciones.html" class="daddy">Conceptos básicos y definiciones</a>
   <ul class="other-section">
      <li><a href="conceptos_previos.html" class="no-ch">Conceptos previos</a></li>
      <li><a href="qu_es_apache_hadoop.html" class="no-ch">¿Qué es Apache Hadoop?</a></li>
      <li><a href="ecosistema_hadoop.html" class="no-ch">Ecosistema Hadoop</a></li>
      <li><a href="quin_usa_hadoop.html" class="no-ch">Quién usa Hadoop</a></li>
      <li><a href="mdulos_de_hadoop.html" class="daddy">Módulos de Hadoop</a>
      <ul class="other-section">
         <li><a href="hadoop_common.html" class="no-ch">Hadoop Common</a></li>
         <li><a href="hadoop_distributed_file_system_hdfs.html" class="no-ch">Hadoop Distributed File System (HDFS™)</a></li>
         <li><a href="hadoop_yarn.html" class="no-ch">Hadoop YARN</a></li>
         <li><a href="hadoop_mapreduce.html" class="no-ch">Hadoop MapReduce</a></li>
         <li><a href="programacin_de_trabajos.html" class="no-ch">Programación de trabajos</a></li>
      </ul>
      </li>
      <li><a href="instalacin_de_hadoop.html" class="daddy">Instalación de Hadoop</a>
      <ul class="other-section">
         <li><a href="prerrequisitos.html" class="daddy">Prerrequisitos</a>
         <ul class="other-section">
            <li><a href="descargar_e_instalar_hadoop.html" class="no-ch">Descargar e instalar Hadoop</a></li>
            <li><a href="actualizar_mquina_virtual.html" class="no-ch">Actualizar máquina virtual</a></li>
            <li><a href="confirmar_versin_de_java.html" class="no-ch">Confirmar versión de Java</a></li>
            <li><a href="crear_y_configurar_los_certificados_ssh.html" class="no-ch">Crear y configurar los certificados SSH</a></li>
         </ul>
         </li>
         <li><a href="modificar_ficheros_de_configuracin.html" class="daddy">Modificar ficheros de configuración</a>
         <ul class="other-section">
            <li><a href="bashrc.html" class="no-ch">~/.bashrc</a></li>
            <li><a href="coresitexml.html" class="no-ch">core-site.xml</a></li>
            <li><a href="hadoopenvsh.html" class="no-ch">hadoop-env.sh</a></li>
            <li><a href="hdfssitexml.html" class="no-ch">hdfs-site.xml</a></li>
            <li><a href="mapredsitexml.html" class="no-ch">mapred-site.xml</a></li>
            <li><a href="yarnsitexml.html" class="no-ch">yarn-site.xml</a></li>
         </ul>
         </li>
         <li><a href="formatear_el_sistema_de_archivos_de_hadoop.html" class="no-ch">Formatear el sistema de archivos de Hadoop</a></li>
         <li><a href="demonios.html" class="daddy">Demonios</a>
         <ul class="other-section">
            <li><a href="arrancar_demonios_hdfs.html" class="no-ch">Arrancar demonios HDFS</a></li>
            <li><a href="arrancar_demonios_yarn.html" class="no-ch">Arrancar demonios Yarn</a></li>
            <li><a href="parar_demonios_hdfs.html" class="no-ch">Parar demonios HDFS</a></li>
            <li><a href="parar_demonios_yarn.html" class="no-ch">Parar demonios Yarn</a></li>
            <li><a href="arrancar_demonios_individualmente.html" class="no-ch">Arrancar demonios individualmente</a></li>
         </ul>
         </li>
      </ul>
      </li>
      <li><a href="interfaces_web_de_hadoop.html" class="daddy">Interfaces Web de Hadoop</a>
      <ul class="other-section">
         <li><a href="namenode_web_interface_hdfs_layer.html" class="no-ch">NameNode Web Interface (HDFS layer)</a></li>
         <li><a href="resource_manager_web_interface_yarn_layer.html" class="no-ch">Resource Manager Web Interface (Yarn layer)</a></li>
         <li><a href="map_reduce_jobhistory.html" class="no-ch">Map Reduce JobHistory</a></li>
      </ul>
      </li>
      <li><a href="ejemplo_comprobacin_instalacin.html" class="no-ch">Ejemplo comprobación instalación</a></li>
      <li><a href="ejercicio_comprobacin_instalacin.html" class="no-ch">Ejercicio: comprobación instalación</a></li>
   </ul>
   </li>
   <li><a href="hdfs.html" class="daddy">HDFS</a>
   <ul class="other-section">
      <li><a href="introduccin.html" class="no-ch">Introducción</a></li>
      <li><a href="arquitectura_hdfs.html" class="no-ch">Arquitectura HDFS</a></li>
      <li><a href="replicacin_de_datos.html" class="no-ch">Replicación de datos</a></li>
      <li><a href="el_nodo_secundario.html" class="no-ch">El nodo secundario</a></li>
      <li><a href="arrancar_hadoop.html" class="no-ch">Arrancar Hadoop</a></li>
      <li><a href="comandos_bsicos_de_hdfs.html" class="no-ch">Comandos básicos de HDFS</a></li>
      <li><a href="ejemplo_de_uso_de_comandos_bsicos_hdfs.html" class="no-ch">Ejemplo de uso de comandos básicos HDFS</a></li>
      <li><a href="api_de_programacin_de_hdfs.html" class="no-ch">API de programación de HDFS</a></li>
      <li><a href="ejercicio1.html" class="daddy">EJERCICIO</a>
      <ul class="other-section">
         <li><a href="a_uso_de_hdfs.html" class="no-ch">A. Uso de HDFS</a></li>
         <li><a href="b_map_reduce.html" class="no-ch">B: Map Reduce</a></li>
         <li><a href="ejercicio2.html" class="no-ch">EJERCICIO</a></li>
      </ul>
      </li>
   </ul>
   </li>
   <li class="current-page-parent"><a href="map_reduce.html" class="current-page-parent daddy">Map Reduce</a>
   <ul>
      <li><a href="procesamiento_en_paralelo.html" class="no-ch">Procesamiento en Paralelo</a></li>
      <li><a href="fundamentos.html" class="no-ch">Fundamentos</a></li>
      <li><a href="ejemplo_sencillo_de_map_reduce.html" class="no-ch">Ejemplo sencillo de map Reduce</a></li>
      <li><a href="explicacin_modelo_map_reduce.html" class="no-ch">Explicación modelo Map Reduce</a></li>
      <li class="current-page-parent"><a href="ejemplo.html" class="current-page-parent daddy">Ejemplo</a>
      <ul>
         <li><a href="datos_de_entrada.html" class="no-ch">Datos de entrada</a></li>
         <li><a href="1_mapeo.html" class="no-ch">1. Mapeo</a></li>
         <li><a href="2_mezcla.html" class="no-ch">2. Mezcla</a></li>
         <li><a href="3_reduccin.html" class="no-ch">3. Reducción</a></li>
         <li id="active"><a href="resultado.html" class="active no-ch">Resultado</a></li>
         <li><a href="interfaz_web.html" class="no-ch">Interfaz Web</a></li>
      </ul>
      </li>
      <li><a href="ejercicio_diccionario.html" class="no-ch">Ejercicio: diccionario</a></li>
      <li><a href="ejercicio_opcional.html" class="no-ch">Ejercicio (opcional)</a></li>
      <li><a href="ms_ejemplos.html" class="no-ch">Más ejemplos</a></li>
   </ul>
   </li>
</ul>
</div>
<div id='topPagination'>
<div class="pagination noprt">
<a href="3_reduccin.html" class="prev"><span>&laquo; </span>Anterior</a> | <a href="interfaz_web.html" class="next"> Siguiente<span> &raquo;</span></a>
</div>
</div>
<div id="main-wrapper">
<div id="main"><a name="main"></a>
<div id="nodeDecoration"><h1 id="nodeTitle">Resultado</h1></div>
<div class="iDevice_wrapper FreeTextIdevice" id="id140">
<div class="iDevice emphasis0">
<div id="ta140_1" class="block iDevice_content">
<p dir="ltr"><span style="font-family: trebuchet ms,geneva; font-size: small;">A continuación se presenta el ejemplo completo. En primer lugar, se parte del siguiente fichero Java que contiene las funciones Map y Reduce.</span></p>
<pre><br /><em><span style="font-size: small; font-family: 'courier new',courier;">import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

  public static class TokenizerMapper
       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    public void map(Object key, Text value, Context context
                    ) throws IOException, InterruptedException {
      StringTokenizer itr = new StringTokenizer(value.toString());
      while (itr.hasMoreTokens()) {
        word.set(itr.nextToken());
        context.write(word, one);
      }
    }
  }

  public static class IntSumReducer
       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,
                       Context context
                       ) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
        sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
    }
  }

  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, "word count");
    job.setJarByClass(WordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}</span></em><span style="font-family: Arial, Verdana, Helvetica, sans-serif; font-size: 0.75em; line-height: 1.5;"> </span></pre>
<p>Debemos generar un jar encargado de ejecutar las funciones anteriores. Para ello se siguen los siguientes pasos:</p>
<p><span>1. Crear un fichero wordcount.java con el código anterior</span></p>
<p><span style="font-family: courier new,courier; font-size: small;">$mkdir mapreduce</span></p>
<p><span style="font-family: courier new,courier; font-size: small;">$cd mapreduce</span></p>
<p><span style="font-family: courier new,courier; font-size: small;">$sudo nano WordCount.java</span></p>
<p><span id="docs-internal-guid-dd5e2e58-72f1-2bab-db31-66590fb3d660"><img src="https://lh6.googleusercontent.com/AAp_rzpjmrUR5Ufn0K-YCVw32QuLZJHPp8wAU_EuUgbfuIMIJKheYESqg_foOaRzO8coGbJRcq-NLRMALmPj5Qn9y9vDRXbOkfXNOT0oL5Lqe5VXqgXpkEfV23HlqRP7SQ" width="534px;" height="59px;" /></span></p>
<p><span>2. Compilar el fichero</span></p>
<p><em><span style="font-family: courier new,courier; font-size: small;">$ javac -classpath $HADOOP_HOME/share/hadoop/common/hadoop-common-2.6.0.jar:$HADOOP_HOME/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar /home/bigdata/mapreduce/WordCount.java</span></em></p>
<p><span id="docs-internal-guid-59b8b72b-7624-d815-06ee-9a72b92520f6"><img src="https://lh6.googleusercontent.com/VqfK2gohGUg2wIkyK4QSljT2acnLXEdkW0ZYw5qFeJ6yQP-NHffkFEeMwwArJGkIACPcBjN4l67NWvenwNH_J23Ekl7xqhXvUU-wjeEj14sRZfH2FXxWlN3ORRkF8sCAgA" width="624px;" height="125px;" /></span></p>
<p><span>3. Crear un jar</span></p>
<p><em><span style="font-family: courier new,courier; font-size: small;">$ jar cf wc.jar WordCount*.class</span></em></p>
<p><span> <span id="docs-internal-guid-59b8b72b-7626-9f04-06ec-0bd50890a3c0"><img src="https://lh5.googleusercontent.com/WImetq-VsSzCNZVaxk4TNserO1XhiMBeVOXxapsalMpayXlBu9V0ThQbklysMgtPfeB4hljdSJYMBfL8ilhyqdilEh2gAGTxM4cAWQdRvgDl1Mz29J3l56hjOZJs0etGeQ" width="624px;" height="83px;" /></span></span></p>
<p dir="ltr"><span>4. Crear los ficheros de entrada de datos</span><span style="font-size: 0.75em; line-height: 1.5;"> </span></p>
<p dir="ltr"><em><span style="font-family: courier new,courier; font-size: small;">$ mkdir wc-in</span></em></p>
<p dir="ltr"><em><span style="font-family: courier new,courier; font-size: small;">$ echo "Hello World. Bye World." &gt; wc-in/a.txt</span></em></p>
<p dir="ltr"><em><span style="font-family: courier new,courier; font-size: small;">$ echo "Hello Hadoop Goodbye Hadoop" &gt; wc-in/b.txt<span style="line-height: 1.5;"> </span></span></em></p>
<p dir="ltr"><span id="docs-internal-guid-59b8b72b-77c0-3f10-8ba3-6216476b456a"><span style="font-size: 0.75em; line-height: 1.5;"> </span><span><img src="https://lh4.googleusercontent.com/PkvYJZyCdGJwvR_mJciy5bc4B5ihvhItY2g4aioOKBSYS1fCPuDUTIXOexO7-INX7kP6HmlOenBfYyvOis-Ak5NlLhSAKiQKNU62QORNyPV9G9D2cN28U8N5T0XDkg6A_g" width="624px;" height="63px;" /></span></span></p>
<p dir="ltr"><span><em><span style="font-family: courier new,courier; font-size: small;">$ hdfs dfs -put wc-in/ /user/bigdata/wc-in</span></em> </span></p>
<p dir="ltr"><span style="font-size: 0.75em; line-height: 1.5;"> </span><span style="font-size: 0.75em; line-height: 1.5;"> <img src="https://lh5.googleusercontent.com/xPVudrcFR9eIi3PDAg0hZOs1zA5ri4zsTPoCmZSrli8yli_6GWRVz9Carec4EcmDrtU0JrKGY6ZRIypyaZ_kioVlU_7qD3gSPQJRIAqPplifufc7o8lyQm_cw_282oPOrQ" width="624px;" height="47px;" /></span></p>
<p dir="ltr"><span>5. Ejecució del jar</span><span style="font-size: 0.75em; line-height: 1.5;"> </span></p>
<p dir="ltr"><span style="font-size: small;"><em><span style="font-family: courier new,courier;">$ hadoop jar wc.jar WordCount wc-in wc-out</span></em></span> <span style="font-size: 0.75em; line-height: 1.5;"> </span></p>
<p dir="ltr"><span id="docs-internal-guid-dd5e2e58-77c4-c34f-1b3d-1b4cd97364e2"><span style="font-size: 0.75em; line-height: 1.5;"> </span><span><img src="https://lh5.googleusercontent.com/dtxyq8ylxTPBpVqYGbHMk5ONXqwyyQApye10Mp_KyTltwdMcfS7U55-uNSmU1mvTA3U1uqn6JSH5eD4k35P0A9WHMOFd2L3SuML6xuFPJ-1ljbgUfBGx5YaU5AcbTbusHA" width="624px;" height="341px;" /></span></span></p>
<p dir="ltr"><em><span style="font-family: courier new,courier; font-size: small;">$ hdfs dfs -cat /user/bigdata/wc-out/part-r00000</span></em></p>
<p dir="ltr"> <span id="docs-internal-guid-dd5e2e58-77c6-93da-63ad-ad9fb2fe098a"><span style="font-size: 0.75em; line-height: 1.5;"> </span><span style="font-size: 0.75em; line-height: 1.5;"> </span><span><img src="https://lh3.googleusercontent.com/5PvsMdWJRpHTxpkxWz5Yjqc-BBSkfuLiKjf4zdHVhWIFyy7pQRSl5VA0ZOHcs1E6kWb4azXa8S7xrGEzMhjS55GWNG-Jh0iI47EN2hXgHC5lbbcpqR9lxXfo8ghQr_7qxA" width="624px;" height="145px;" /></span></span></p>
</div>
</div>
</div>
</div>
</div>
<div id='bottomPagination'>
<div class="pagination noprt">
<a href="3_reduccin.html" class="prev"><span>&laquo; </span>Anterior</a> | <a href="interfaz_web.html" class="next"> Siguiente<span> &raquo;</span></a>
</div>
</div>
</div>
</body></html>